{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f30611fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# 1. LOAD LIBRARIES AND CONFIG\n",
    "# -------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# Import config paths so they are accessible to module.\n",
    "import sys\n",
    "sys.path.insert(0, \"C:/Misc/binary_eval\")\n",
    "import config\n",
    "import importlib\n",
    "importlib.reload(config)    # Reload config to ensure latest edits are active\n",
    "\n",
    "from config import  OUTPUTS_DIR, PROCESSED_DATA_DIR, BASELINE_RESULTS_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c84e6b",
   "metadata": {},
   "source": [
    "This cell defines the AVAILABLE_MODELS dictionary, which lists all machine learning classifiers used for baseline evaluation. Each entry includes the modelâ€™s class, module, label requirements, hyperparameter search type, scoring metric, default parameters, and grid search options. \n",
    "\n",
    "This structure enables modular, reproducible benchmarking across diverse datasets and supports automated model selection and tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e99eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# 2. INSTANTIATE MODELS\n",
    "# -------------------------------------------\n",
    "\n",
    "AVAILABLE_MODELS = {\n",
    "    \"DecisionTreeClassifier\": {\n",
    "        \"class\": \"DecisionTreeClassifier\",\n",
    "        \"module\": \"sklearn.tree\",\n",
    "        \"requires_numeric_labels\": False,\n",
    "        \"search_type\": \"grid\",\n",
    "        \"scoring\": \"accuracy\",\n",
    "        \"default_params\": {\"random_state\": 42},\n",
    "        \"param_grid\": {\n",
    "            \"criterion\": [\"gini\", \"entropy\"],\n",
    "            \"max_depth\": [None, 10, 20],\n",
    "            \"min_samples_split\": [2, 5],\n",
    "            \"min_samples_leaf\": [1, 3],\n",
    "            \"max_features\": [None]\n",
    "        }\n",
    "    },\n",
    "    \"RandomForestClassifier\": {\n",
    "        \"class\": \"RandomForestClassifier\",\n",
    "        \"module\": \"sklearn.ensemble\",\n",
    "        \"requires_numeric_labels\": False,\n",
    "        \"search_type\": \"grid\",\n",
    "        \"scoring\": \"accuracy\",\n",
    "        \"default_params\": {\n",
    "            \"random_state\": 42,\n",
    "            \"n_jobs\": -1\n",
    "        },\n",
    "        \"param_grid\": {\n",
    "            \"n_estimators\": [100, 300],\n",
    "            \"max_depth\": [None, 30],\n",
    "            \"min_samples_split\": [2, 10],\n",
    "            \"min_samples_leaf\": [1, 5],\n",
    "            \"max_features\": [\"sqrt\"]\n",
    "        }\n",
    "    },\n",
    "    \"ExtraTreesClassifier\": {\n",
    "        \"class\": \"ExtraTreesClassifier\",\n",
    "        \"module\": \"sklearn.ensemble\",\n",
    "        \"requires_numeric_labels\": False,\n",
    "        \"search_type\": \"grid\",\n",
    "        \"scoring\": \"accuracy\",\n",
    "        \"default_params\": {\n",
    "            \"random_state\": 42,\n",
    "            \"n_jobs\": -1\n",
    "        },\n",
    "        \"param_grid\": {\n",
    "            \"n_estimators\": [100, 300],\n",
    "            \"max_depth\": [None, 10, 30],\n",
    "            \"min_samples_split\": [2, 10],\n",
    "            \"min_samples_leaf\": [1, 5],\n",
    "            \"max_features\": [\"sqrt\"]\n",
    "        }\n",
    "    },\n",
    "    \"GradientBoostingClassifier\": {\n",
    "        \"class\": \"GradientBoostingClassifier\",\n",
    "        \"module\": \"sklearn.ensemble\",\n",
    "        \"requires_numeric_labels\": False,\n",
    "        \"search_type\": \"grid\",\n",
    "        \"scoring\": \"accuracy\",\n",
    "        \"default_params\": {\n",
    "            \"random_state\": 42,\n",
    "            \"subsample\": 0.8,\n",
    "            \"max_depth\": 5,\n",
    "            \"max_features\": \"sqrt\"\n",
    "        },\n",
    "        \"param_grid\": {\n",
    "            \"n_estimators\": [100]\n",
    "        }\n",
    "    },\n",
    "    \"LGBMClassifier\": {\n",
    "        \"class\": \"LGBMClassifier\",\n",
    "        \"module\": \"lightgbm\",\n",
    "        \"requires_numeric_labels\": True,\n",
    "        \"search_type\": \"grid\",\n",
    "        \"scoring\": \"accuracy\",\n",
    "        \"default_params\": {\n",
    "            \"random_state\": 42,\n",
    "            \"n_jobs\": -1,\n",
    "            \"verbose\": -1\n",
    "        },\n",
    "        \"param_grid\": {\n",
    "            \"n_estimators\": [100],\n",
    "            \"num_leaves\": [15, 31]\n",
    "        }\n",
    "    },\n",
    "    \"XGBClassifier\": {\n",
    "        \"class\": \"XGBClassifier\",\n",
    "        \"module\": \"xgboost\",\n",
    "        \"requires_numeric_labels\": True,\n",
    "        \"search_type\": \"grid\",\n",
    "        \"scoring\": \"accuracy\",\n",
    "        \"default_params\": {\n",
    "            \"random_state\": 42,\n",
    "            \"use_label_encoder\": False,\n",
    "            \"eval_metric\": \"mlogloss\",\n",
    "            \"n_jobs\": -1,\n",
    "            \"verbosity\": 0\n",
    "        },\n",
    "        \"param_grid\": {\n",
    "            \"n_estimators\": [100, 300],\n",
    "            \"learning_rate\": [0.01, 0.1],\n",
    "            \"max_depth\": [3, 7],\n",
    "            \"subsample\": [0.8, 1.0]\n",
    "        }\n",
    "    },\n",
    "    \"LogisticRegression\": {\n",
    "        \"class\": \"LogisticRegression\",\n",
    "        \"module\": \"sklearn.linear_model\",\n",
    "        \"requires_numeric_labels\": False,\n",
    "        \"search_type\": \"grid\",\n",
    "        \"scoring\": \"accuracy\",\n",
    "        \"default_params\": {\n",
    "            \"random_state\": 42,\n",
    "            \"solver\": \"liblinear\"\n",
    "        },\n",
    "        \"param_grid\": {\n",
    "            \"penalty\": [\"l1\", \"l2\"],\n",
    "            \"C\": [0.01, 0.1, 1, 10, 100]\n",
    "        }\n",
    "    },\n",
    "    \"SGDClassifier\": {\n",
    "        \"class\": \"SGDClassifier\",\n",
    "        \"module\": \"sklearn.linear_model\",\n",
    "        \"requires_numeric_labels\": False,\n",
    "        \"search_type\": \"grid\",\n",
    "        \"scoring\": \"accuracy\",\n",
    "        \"default_params\": {\n",
    "            \"random_state\": 42,\n",
    "            \"n_jobs\": -1,\n",
    "            \"max_iter\": 1000\n",
    "        },\n",
    "        \"param_grid\": {\n",
    "            \"loss\": [\"hinge\", \"log_loss\"],\n",
    "            \"penalty\": [\"l2\", \"elasticnet\"],\n",
    "            \"alpha\": [0.0001, 0.001],\n",
    "            \"max_iter\": [1000, 2000]\n",
    "        }\n",
    "    },\n",
    "    \"LinearSVC\": {\n",
    "        \"class\": \"LinearSVC\",\n",
    "        \"module\": \"sklearn.svm\",\n",
    "        \"requires_numeric_labels\": False,\n",
    "        \"search_type\": \"grid\",\n",
    "        \"scoring\": \"accuracy\",\n",
    "        \"default_params\": {\n",
    "            \"random_state\": 42,\n",
    "            \"max_iter\": 1000\n",
    "        },\n",
    "        \"param_grid\": {\n",
    "            \"C\": [0.1, 1, 10],\n",
    "            \"loss\": [\"hinge\", \"squared_hinge\"]\n",
    "        }\n",
    "    },\n",
    "    \"SVC\": {\n",
    "        \"class\": \"SVC\",\n",
    "        \"module\": \"sklearn.svm\",\n",
    "        \"requires_numeric_labels\": False,\n",
    "        \"search_type\": \"grid\",\n",
    "        \"scoring\": \"accuracy\",\n",
    "        \"default_params\": {\n",
    "            \"random_state\": 42\n",
    "        },\n",
    "        \"param_grid\": {\n",
    "            \"C\": [0.1, 1, 10],\n",
    "            \"kernel\": [\"linear\", \"rbf\"],\n",
    "            \"gamma\": [\"scale\", \"auto\"],\n",
    "            \"max_iter\": [-1]\n",
    "        }\n",
    "    },\n",
    "    \"KNeighborsClassifier\": {\n",
    "        \"class\": \"KNeighborsClassifier\",\n",
    "        \"module\": \"sklearn.neighbors\",\n",
    "        \"requires_numeric_labels\": False,\n",
    "        \"search_type\": \"grid\",\n",
    "        \"scoring\": \"accuracy\",\n",
    "        \"default_params\": {},\n",
    "        \"param_grid\": {\n",
    "            \"n_neighbors\": [3, 5, 7],\n",
    "            \"weights\": [\"uniform\", \"distance\"],\n",
    "            \"metric\": [\"euclidean\", \"manhattan\"],\n",
    "            \"p\": [1, 2]\n",
    "        }\n",
    "    },\n",
    "    \"GaussianNB\": {\n",
    "        \"class\": \"GaussianNB\",\n",
    "        \"module\": \"sklearn.naive_bayes\",\n",
    "        \"requires_numeric_labels\": False,\n",
    "        \"search_type\": \"grid\",\n",
    "        \"scoring\": \"accuracy\",\n",
    "        \"default_params\": {},\n",
    "        \"param_grid\": {\n",
    "            \"var_smoothing\": [1e-9, 1e-8, 1e-7, 1e-6]\n",
    "        }\n",
    "    },\n",
    "    \"LinearDiscriminantAnalysis\": {\n",
    "        \"class\": \"LinearDiscriminantAnalysis\",\n",
    "        \"module\": \"sklearn.discriminant_analysis\",\n",
    "        \"requires_numeric_labels\": False,\n",
    "        \"search_type\": \"grid\",\n",
    "        \"scoring\": \"accuracy\",\n",
    "        \"default_params\": {}, # svd w/ shrinkage will crash\n",
    "        \"param_grid\": {\n",
    "            \"solver\": [\"lsqr\", \"eigen\"],\n",
    "            \"shrinkage\": [\"auto\"]  # Only used with 'lsqr' and 'eigen'\n",
    "        }\n",
    "    },\n",
    "    \"QuadraticDiscriminantAnalysis\": {\n",
    "        \"class\": \"QuadraticDiscriminantAnalysis\",\n",
    "        \"module\": \"sklearn.discriminant_analysis\",\n",
    "        \"requires_numeric_labels\": False,\n",
    "        \"search_type\": \"grid\",\n",
    "        \"scoring\": \"accuracy\",\n",
    "        \"default_params\": {},\n",
    "        \"param_grid\": {\n",
    "            \"reg_param\": [0.0, 0.01, 0.1, 0.5],\n",
    "            \"store_covariance\": [False]  # Set to True only if you need access to covariances\n",
    "        }\n",
    "    },\n",
    "    \"MLPClassifier\": {\n",
    "        \"class\": \"MLPClassifier\",\n",
    "        \"module\": \"sklearn.neural_network\",\n",
    "        \"requires_numeric_labels\": False,\n",
    "        \"search_type\": \"grid\",\n",
    "        \"scoring\": \"accuracy\",\n",
    "        \"default_params\": {\n",
    "            \"random_state\": 42,\n",
    "            \"max_iter\": 1000\n",
    "        },\n",
    "        \"param_grid\": {\n",
    "            \"hidden_layer_sizes\": [(50,), (100,)],\n",
    "            \"activation\": [\"relu\", \"tanh\"],\n",
    "            \"solver\": [\"adam\", \"sgd\"],\n",
    "            \"learning_rate_init\": [0.001, 0.01]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Save AVAILABLE_MODELS to outputs/pre_tuned_models/available_models.json\n",
    "models_path = OUTPUTS_DIR / \"pre_tuned_models\" / \"available_models.json\"\n",
    "models_path.parent.mkdir(parents=True, exist_ok=True)  # Ensure directory exists\n",
    "\n",
    "with open(models_path, \"w\") as f:\n",
    "    json.dump(AVAILABLE_MODELS, f, indent=2)\n",
    "\n",
    "print(\"Available Models:\")\n",
    "for idx, model_name in enumerate(AVAILABLE_MODELS.keys(), 1):\n",
    "    print(f\"{idx}. {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec43d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# 3. SELECT MODEL TO EVALUATE\n",
    "# -------------------------------------------\n",
    "\n",
    "# Modules 05, 06, and 07 are run sequentially to evaluate one model on one dataset.\n",
    "# This approach was chosen because some models took hours to run on some datasets.\n",
    "\n",
    "# ---------------- CHOOSE MODEL TO EVALUATE ----------------\n",
    "selected_model = \"MLPClassifier\"   # <-- Copy/paste from printed list above\n",
    "#-----------------------------------------------------------\n",
    "#  CHANGE MODEL FOR  EACH ROUND: One round is executing 05, 06, and 07 modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51aa534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# 4. LOAD TRANSFORMED DATASET\n",
    "# -------------------------------------------\n",
    "# -------------------- SELECT THE DATASET --------------------\n",
    "#  Do not use .csv extension in the name\n",
    "dataset_name = \"dataset1\"  # <-- Replace with actual dataset name. Exclude extension \".csv\"\n",
    "\n",
    "# Build the path to the transformed parquet file\n",
    "transformed_path = PROCESSED_DATA_DIR / f\"{dataset_name}_transformed.parquet\"\n",
    "\n",
    "# Load the transformed dataset\n",
    "df = pd.read_parquet(transformed_path)\n",
    "\n",
    "print(f\"Loaded transformed dataset: {transformed_path}\")\n",
    "print(f\"Shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afe800f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# 5. SPLIT FEATURES AND TARGET\n",
    "# -------------------------------------------\n",
    "\n",
    "# Specify the target column name\n",
    "target_col = \"target\"  # <-- Replace with actual target column name if needed\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "# Diagnostics\n",
    "print(\"Target preview:\", y.head())\n",
    "print(\"Unique values:\", y.unique())\n",
    "print(\"Target dtype:\", y.dtype)\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea296e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# 5a. SANITIZE COLUMN NAMES BECAUSE ONE-HOT ENCODING CAN CREATE PROBLEMS\n",
    "# -------------------------------------------\n",
    "\n",
    "\n",
    "# Sanitize column names after one-hot encoding to prevent model crashes.\n",
    "# LightGBM and similar libraries require feature names to be ASCII, printable, and free of control characters.\n",
    "# One-hot encoding creates new columns using raw categorical values, which may contain spaces, punctuation,\n",
    "# Unicode, or invisible/control characters. Sanitizing ensures robust, error-free model training.\n",
    "\n",
    "# Problematic characters in column names that could cause model crashes include:\n",
    "#  1. Invisible Unicode characters (e.g., zero-width space, non-breaking space)\n",
    "#  2. Non-ASCII symbols\n",
    "#  3. Hidden formatting or control characters\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "def sanitize_column_names(columns):\n",
    "    # Remove any character that is not a letter, digit, or underscore\n",
    "    return [re.sub(r'[^\\w]', '_', str(col)) for col in columns]\n",
    "\n",
    "# Apply to your features\n",
    "X.columns = sanitize_column_names(X.columns)\n",
    "print(\"Sanitized columns:\", X.columns.tolist())\n",
    "\n",
    "for col in X.columns:\n",
    "    for c in col:\n",
    "        if ord(c) < 32 or ord(c) > 126:\n",
    "            print(f\"Non-printable character found in column: {col!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bf3bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# 6. CROSS-VALIDATION: ACCURACY, F1, ROC AUC\n",
    "# -------------------------------------------\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import importlib\n",
    "\n",
    "# ---- Instantiate the selected model ----\n",
    "model_info = AVAILABLE_MODELS[selected_model]\n",
    "model_module = importlib.import_module(model_info[\"module\"])\n",
    "ModelClass = getattr(model_module, model_info[\"class\"])\n",
    "model = ModelClass(**model_info[\"default_params\"])\n",
    "\n",
    "# Show model being evaluated.\n",
    "print(f\"Evaluating this model: {model}\")\n",
    "print()\n",
    "\n",
    "# ---- Set up StratifiedKFold ----\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# ---- Compute metrics ----\n",
    "metrics = {\n",
    "    \"accuracy\": \"accuracy\",\n",
    "    \"f1_weighted\": \"f1_weighted\",\n",
    "    \"roc_auc\": \"roc_auc_ovr\"\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for metric_name, scoring in metrics.items():\n",
    "    scores = cross_val_score(model, X, y, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "    results[metric_name] = {\n",
    "        \"mean\": scores.mean(),\n",
    "        \"std\": scores.std(),\n",
    "        \"all_scores\": scores.tolist()\n",
    "    }\n",
    "\n",
    "# ---- Print results ----\n",
    "for metric_name, stats in results.items():\n",
    "    print(f\"{metric_name.capitalize()} - Mean: {stats['mean']:.4f}, Std: {stats['std']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e24f079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# 7 CONSTRUCT PARAMS METADATA COLUMN\n",
    "# -------------------------------------------\n",
    "\n",
    "# This cell constructs the params metadata column using only param_grid\n",
    "# keys and their default values. \n",
    "\n",
    "# To capture the actual values used (including library defaults),\n",
    "# this code uses model.get_params() for the parameters of importance\n",
    "# for this module (i.e., those in param_grid of each model). This ensures\n",
    "# that the params data recorded in the Excel file model_results_baseline.xlsx\n",
    "# are the actual values used by the model.\n",
    "\n",
    "# This ensures the params column reflects\n",
    "# the baseline (untuned) configuration for the selected model.\n",
    "\n",
    "model_info = AVAILABLE_MODELS[selected_model]\n",
    "param_grid_keys = list(model_info[\"param_grid\"].keys())\n",
    "default_params = model_info[\"default_params\"]\n",
    "\n",
    "# Build params dictionary from the model's actual default values\n",
    "params_metadata = {key: model.get_params().get(key, None) for key in param_grid_keys}\n",
    "\n",
    "print(\"Params metadata for baseline run:\")\n",
    "print(params_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd13b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# 8. MEASURE PEAK RAM USAGE AND THROUGHPUT FOR PREDICTION ONLY\n",
    "# -------------------------------------------\n",
    "\n",
    "# Turn off all other apps to reduce interuptions and make\n",
    "# the benchmarking results more stable and reporducible.\n",
    "\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "# Show model being evaluated.\n",
    "print(f\"Evaluating this model: {model}\")\n",
    "print()\n",
    "\n",
    "\n",
    "n_loops = 5\n",
    "max_ram_mb = 0\n",
    "total_predictions = 0\n",
    "total_pred_runtime = 0.0\n",
    "\n",
    "process = psutil.Process()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the model once before prediction loops\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "for i in range(n_loops):\n",
    "    start_ram = process.memory_info().rss / (1024 ** 2)  # MB\n",
    "    \n",
    "    pred_start = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    pred_end = time.time()\n",
    "    \n",
    "    ram_after_pred = process.memory_info().rss / (1024 ** 2)  # MB\n",
    "    max_ram_mb = max(max_ram_mb, start_ram, ram_after_pred)\n",
    "    n_preds = len(X_test)\n",
    "    total_predictions += n_preds\n",
    "    loop_pred_runtime = pred_end - pred_start    # Calculate total runtime\n",
    "    total_pred_runtime += loop_pred_runtime\n",
    "\n",
    "\n",
    "# Calculate throughput for prediction only\n",
    "throughput = total_predictions / total_pred_runtime if total_pred_runtime > 0 else 0\n",
    "\n",
    "print(f\"Peak RAM usage during prediction over {n_loops} loops: {max_ram_mb:.2f} MB\")\n",
    "print(f\"Total predictions made: {total_predictions:,.2f}\")\n",
    "print(f\"Total cumulative prediction runtime: {total_pred_runtime:.4f} seconds\")\n",
    "print(f\"Prediction throughput (predictions/sec): {throughput:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c2016d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# 8. DISPLAY ACTUAL HYPERPARAMETERS\n",
    "# -------------------------------------------\n",
    "\n",
    "\n",
    "# Confirm the actual hyperparameters used by the fitted model\n",
    "print(f\"Actual hyperparameters for {selected_model}:\")\n",
    "for param, value in model.get_params().items():\n",
    "    print(f\"{param}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c038418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# 9. EXPORT BASELINE (PRE-TUNING) RESULTS TO EXCEL\n",
    "# -------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# --- Prepare results row with all required metadata ---\n",
    "results_row = {\n",
    "    \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"model_name\": selected_model,\n",
    "    \"dataset\": dataset_name,\n",
    "    \"n_samples\": X.shape[0],\n",
    "    \"n_features\": X.shape[1],\n",
    "    \"fit_loops\": n_loops,\n",
    "    \"params\": str(params_metadata),\n",
    "    \"accuracy_mean\": results[\"accuracy\"][\"mean\"],\n",
    "    \"accuracy_std\": results[\"accuracy\"][\"std\"],\n",
    "    \"f1_weighted_mean\": results[\"f1_weighted\"][\"mean\"],\n",
    "    \"f1_weighted_std\": results[\"f1_weighted\"][\"std\"],\n",
    "    \"auc_mean\": results[\"roc_auc\"][\"mean\"],\n",
    "    \"auc_std\": results[\"roc_auc\"][\"std\"],\n",
    "    \"runtime_total\": total_pred_runtime,\n",
    "    \"peak_ram_mb\": max_ram_mb,\n",
    "    \"throughput\": throughput\n",
    "}\n",
    "\n",
    "# --- Save to Excel in outputs/baseline_results ---\n",
    "excel_path = BASELINE_RESULTS_DIR / \"model_results_baseline.xlsx\"\n",
    "excel_path.parent.mkdir(parents=True, exist_ok=True)  # Ensure directory exists\n",
    "df_results = pd.DataFrame([results_row])\n",
    "if excel_path.exists():\n",
    "    existing = pd.read_excel(excel_path)\n",
    "    df_results = pd.concat([existing, df_results], ignore_index=True)\n",
    "df_results.to_excel(excel_path, index=False)\n",
    "\n",
    "print(f\"Results saved to: {excel_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab2da0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# 10. SAVE MODEL AND DATASET SELECTION\n",
    "# -------------------------------------------\n",
    "\n",
    "# Save selected_model and dataset_name to a file\n",
    "# which will be used by the 06_tune_hyperparameters module.\n",
    "selection = {\n",
    "    \"selected_model\": selected_model,\n",
    "    \"dataset_name\": dataset_name\n",
    "}\n",
    "with open(OUTPUTS_DIR / \"last_selection.json\", \"w\") as f:\n",
    "    json.dump(selection, f)\n",
    "\n",
    "selection_path = OUTPUTS_DIR / \"last_selection.json\"\n",
    "print(f\"Model name and file name were saved to: {selection_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
