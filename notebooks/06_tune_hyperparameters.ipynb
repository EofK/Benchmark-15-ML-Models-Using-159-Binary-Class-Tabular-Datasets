{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd9a97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# 1. LOAD LIBRARIES AND CONFIG\n",
    "# -------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "# Import config paths so they are accessible to module.\n",
    "import sys\n",
    "sys.path.insert(0, \"C:/Misc/binary_eval\")\n",
    "import config\n",
    "import importlib\n",
    "importlib.reload(config)    # Reload config to ensure latest edits are active\n",
    "\n",
    "from config import DATASETS_DIR, TUNED_MODELS_DIR, PROCESSED_DATA_DIR, OUTPUTS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8867,
   "id": "0451c453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# 2. LOAD MODELS\n",
    "# -------------------------------------------\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "# Load AVAILABLE_MODELS created in 04_prepare_model_baselines.ipynb\n",
    "models_path = OUTPUTS_DIR / \"pre_tuned_models\" / \"available_models.json\"\n",
    "\n",
    "with open(models_path, \"r\") as f:\n",
    "    AVAILABLE_MODELS = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8d2582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# 3. OBTAIN MODEL NAME AND DATASET NAME\n",
    "# -------------------------------------------\n",
    "\n",
    "# Obtain selected model and dataset names set in the previous module 05_prepare_model_baselines.ipynb\n",
    "with open(OUTPUTS_DIR / \"last_selection.json\", \"r\") as f:\n",
    "    selection = json.load(f)\n",
    "selected_model = selection[\"selected_model\"]\n",
    "dataset_name = selection[\"dataset_name\"]\n",
    "\n",
    "print(f\"Selected model: {selected_model}\")\n",
    "print(f\"Selected dataset: {dataset_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab337cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# 4. LOAD DATASET AND SPLIT FEATURES/TARGET\n",
    "# -------------------------------------------\n",
    "\n",
    "# Build the path to the processed dataset\n",
    "transformed_path = PROCESSED_DATA_DIR / f\"{dataset_name}_transformed.parquet\"\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_parquet(transformed_path)\n",
    "\n",
    "# Specify the target column name. Every dataset for this project used \"target\".\n",
    "target_col = \"target\"  \n",
    "\n",
    "# Split into features and target\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e81245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# 4a. SANITIZE COLUMN NAMES BECAUSE ONE-HOT ENCODING CAN CREATE PROBLEMS\n",
    "# -------------------------------------------\n",
    "\n",
    "\n",
    "# Sanitize column names after one-hot encoding to prevent model crashes.\n",
    "# LightGBM and similar libraries require feature names to be ASCII, printable, and free of control characters.\n",
    "# One-hot encoding creates new columns using raw categorical values, which may contain spaces, punctuation,\n",
    "# Unicode, or invisible/control characters. Sanitizing ensures robust, error-free model training.\n",
    "\n",
    "# Problematic characters in column names that could cause model crashes include:\n",
    "#  1. Invisible Unicode characters (e.g., zero-width space, non-breaking space)\n",
    "#  2. Non-ASCII symbols\n",
    "#  3. Hidden formatting or control characters\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "def sanitize_column_names(columns):\n",
    "    # Remove any character that is not a letter, digit, or underscore\n",
    "    return [re.sub(r'[^\\w]', '_', str(col)) for col in columns]\n",
    "\n",
    "# Apply to your features\n",
    "X.columns = sanitize_column_names(X.columns)\n",
    "print(\"Sanitized columns:\", X.columns.tolist())\n",
    "\n",
    "for col in X.columns:\n",
    "    for c in col:\n",
    "        if ord(c) < 32 or ord(c) > 126:\n",
    "            print(f\"Non-printable character found in column: {col!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f0c233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# 5. SET UP HYPERPARAMETER SEARCH (GridSearchCV)\n",
    "# -------------------------------------------\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import importlib\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# Get model info and param grid\n",
    "model_info = AVAILABLE_MODELS[selected_model]\n",
    "param_grid = model_info[\"param_grid\"]\n",
    "n_param_combinations = len(ParameterGrid(param_grid))   # Permutations of params and value choices.\n",
    "\n",
    "# Dynamically import the model class\n",
    "model_module = importlib.import_module(model_info[\"module\"])\n",
    "ModelClass = getattr(model_module, model_info[\"class\"])\n",
    "\n",
    "# Instantiate the model with default parameters\n",
    "model = ModelClass(**model_info[\"default_params\"])\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    scoring=model_info.get(\"scoring\", \"accuracy\"),\n",
    "    n_jobs=-1,  # Need 1 to limit to one job for some models (e.g., LR). Else -1\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "print(\"GridSearchCV is set up and ready to run.\")\n",
    "print(f\"Number of parameter combinations: {n_param_combinations:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fc72ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# 6. RUN HYPERPARAMETER TUNING\n",
    "# -------------------------------------------\n",
    "\n",
    "# Show model being tuned.\n",
    "print(f\"Evaluating this model: {model}\")\n",
    "print()\n",
    "\n",
    "\n",
    "# The code below uses the entire dataset for tuning\n",
    "X_sample = X\n",
    "y_sample = y\n",
    "sample_size = len(X_sample)   # If entire dataset is used, this is the sample size.\n",
    "\n",
    "\n",
    "# But a random sample can be selected if RAM is insufficient for the full dataset.\n",
    "sample_size = min(30000, len(X))\n",
    "X_sample = X.sample(n=sample_size, random_state=42)\n",
    "y_sample = y.loc[X_sample.index]\n",
    "\n",
    "print(f\"\\nUsing {sample_size:,} rows for tuning.\\n\")\n",
    "\n",
    "# Determine best params and measure time to do that.\n",
    "\n",
    "start_time = time.time()\n",
    "grid_search.fit(X_sample, y_sample)\n",
    "end_time = time.time()\n",
    "grid_runtime = end_time - start_time\n",
    "\n",
    "print(f\"GridSearchCV runtime: {grid_runtime:.2f} seconds\")\n",
    "print()\n",
    "\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "best_estimator = grid_search.best_estimator_\n",
    "\n",
    "print(best_params)\n",
    "print(f\"Best CV Score: {best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f4473b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# 7. DISPLAY HYPERPARAMETERS AND TUNING STATUS\n",
    "# -------------------------------------------\n",
    "\n",
    "# Get all hyperparameters from the best estimator\n",
    "all_params = best_estimator.get_params()\n",
    "\n",
    "# Get the param_grid keys (tuned hyperparameters)\n",
    "tuned_keys = set(param_grid.keys())\n",
    "\n",
    "\n",
    "print(f\"The Hyperparameters and Tuning Values for: {selected_model}\")\n",
    "print()\n",
    "for param, value in all_params.items():\n",
    "    if param in tuned_keys:\n",
    "        status = \"ðŸŸ¢ Tuned\"\n",
    "    else:\n",
    "        status = \"âšª Default\"\n",
    "    print(f\"{param}: {value}   {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f157b5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# 8. EXPORT TUNING RESULTS AND METADATA TO JSON\n",
    "# -------------------------------------------\n",
    "\n",
    "# Export the tuning results and best parameters to a JSON file in\n",
    "# the tuned_models directory. This file includes all metadata\n",
    "# needed for downstream modules to build and instantiate\n",
    "# the now-tuned model. \n",
    "\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Prepare results dictionary which is used to populate the JSON results file.\n",
    "tuning_results = {\n",
    "    \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"model_name\": selected_model,\n",
    "    \"model_module\": model_info[\"module\"],\n",
    "    \"dataset\": dataset_name,\n",
    "    \"best_params\": best_params,\n",
    "    \"best_score\": best_score,\n",
    "    \"param_grid\": param_grid,\n",
    "    \"all_params\": best_estimator.get_params(),\n",
    "    \"n_features\": X.shape[1],\n",
    "    \"n_samples\": X.shape[0],\n",
    "    \"grid_runtime\": grid_runtime,\n",
    "    \"param_combinations\": n_param_combinations,\n",
    "    \"hyper_tune_sample_size\": sample_size\n",
    "}\n",
    "\n",
    "# Save to outputs/tuned_models for use by 07_run_model_evaluation.ipynb\n",
    "results_path = TUNED_MODELS_DIR / f\"{selected_model}_{dataset_name}_tuning_results.json\"\n",
    "results_path.parent.mkdir(parents=True, exist_ok=True)  # Ensure directory exists\n",
    "\n",
    "with open(results_path, \"w\") as f:\n",
    "    json.dump(tuning_results, f, indent=2)\n",
    "\n",
    "print(f\"Tuning results and metadata saved to: {results_path}\")\n",
    "\n",
    "print(\"Here are tuned parameters\")\n",
    "print(model.get_params())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
